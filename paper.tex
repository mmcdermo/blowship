\documentclass[twocolumn,11pt,english]{article}
\usepackage{comment}
\usepackage{tikz}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{cite}
\usepackage{relsize}
\usepackage[T1]{fontenc}
\usepackage[margin=1.0in]{geometry}

\title{Blowship - Untraceable Instantaneous Message Transfer via a Central Server}
\date{}
\author{
  Carlyle, John\\
  \textit{jcarlyle@ucsc.edu}
  \and
  McDermott, Morgan\\
  \textit{mmcdermo@ucsc.edu}
}


\begin{document}
\maketitle

\section*{Abstract} 
Many systems have been developed that preserve the anonymity of the sender and receiver of data. These systems are typically decentralized, routing messages through some series of trusted or untrusted peers and servers. 

In this paper we present a centralized anonymity system that uses a single, untrusted central server, adapting decentralized peer-to-peer (P2P) protocols to work in this context, and combine these with Computational Private Information Retrieval (CPIR) to enable low-latency, low-overhead anonymous communication. The primary reason behind a centeral server is to have a browser based service which needs a server to initialze the P2P network.

\section{Introduction}

Traditional cryptography hides the message being sent from one party to another. This is useful for many purposes but there is an important aspect of your communication that is freely availble to anyone observing the transfer: to whom the message is sent. Much work has been done to build networks that can obscure message passing by esentially mixing the messages around in a large group of peers in such a way that a peer in the network, or even a large group of peers, cannot figure out the message's final destination. Many of these systems rely upon the fact that the user is accessing a constantly avaible resource, such as with Tor\cite{tor-design}, or in the case of email one can wait as long as nessesary for a message to be read by the recipient.

We present to the reader Untraceable Instantaneous Messaging, via a central server. Our message passing system is initiated by the browser, allowing a person to browse to one central location and conveniently use this service. A much different experience than with using many other P2P communication protocols. The central server is primarily used as an entrypoint into a network of peers. The peers are used to obsfucate who is sending messages to whom, allowing the clients to communicate with both private content and correspondant, all in as close to real time as possible given the constraints of the algorithms being used.

\section{Conventions}
All logs in this paper are $\log_2$ unless otherwise specified. $N$ is the total number of peers in the network. A \textit{hop} is defined as a message passing from $peer_a$ to the server and then to $peer_b$, for reasons explained in section 5.

\subsection{Measuring Anonymity}
Anonymity sets \cite{chaum-dc}, are widely used to analyze the anonymity provided by various P2P privacy schemes. Given a message and whatever information an attacker has obtained, the anonymity set for that message is the set of users who could have sent it. For example, an anonymity set of size 1 means that the attacker knows exactly who sent the message.

This measure fails to capture some of the information gathered by the attacker. If, for instance, certain members of an anonymity set are more likely to have sent the message (which is never the case in Chaum's DC networks \cite{chaum-dc}), this information is not captured by the size of the anonymity set. 

To solve this problem, Diaz \cite{Diaz02} and Serjantov \cite{Serj02} independently developed almost identical solutions. Their solution is this: given a message, consider the probability distribution of its senders. The entropy of this probability distribution then represents the number of bits an attacker still needs to obtain in order to identify the sender of the message. 

Serjantov \cite{Serj02} calls this measure the \textit{size} $S$ of the anonymity probability distribution. Given $U$, the set of all users, and $p_u$, the probability that $u \in U$ sent the message, then the $size$ of the probability distribution is:

\begin{center}
  $ S = - \mathlarger{\sum}\limits_{u \in U} p_u \log_2(p_u)$
\end{center}

Suppose we have a user such that his or her probability is $1$, then  $S = -(1 * 0) = 0$, meaning the attacker needs no more information to identify the user. 


\subsection{Adversaries}
In this context, we have several distinct types of adversaries we must consider:
\begin{description}
\item[Penguin] 
  is any Peer who can intercept any messages and modify the content of that message.
\item[Surge] 
  is a compromised central Server. He can alter and intercept any messages passing through, and can provide bogus information to any peer.
\item[Proletariat] 
  is a group of colluding Penguins.
\item[The Fort] 
  is Surge and a Proletariat colluding. In this situation Surge could be generating new peers to act as Penguins in order to form The Fort.
\end{description}

\section{Previous Work}
The majority of research into anonymous communication uses decentralized P2P networks. In some cases, however, it is necessary (and possibly beneficial) to communicate through a central server. 

\subsection{Mixes}
Mixes are servers through which encrypted messages are sent, hiding the correlation between incoming and outgoing messages using encryption, pooling incoming messages, and a variety of other strategies. Mixes have seen wide use since Chaum first introduced them in 1981 \cite{chaum-mix}. They have been used in systems such as MixMinion\cite{minion-design} to anonymously send and receive email. Onion routing systems such as Tor \cite{tor-design} use a series of mixes as proxies for web data. 

\subsection{Nym systems} Pseudonymous message delivery systems enable users to send and receive messages with a \textit{nym} (pseudonym) that cannot be traced back to their true identity. Many of these systems rely on having an anonymous ``forward'' channel that allows a user to send a message without attackers being able to deduce the recipient - which is what we develop in this paper. 

\subsection{Private Information Retrieval} Private Information Retrieval (PIR) has been used to facilitate anonymous communication in a variety of ways. The Pynchon Gate \cite{sassaman:wpes2005} is a nym system that uses information-theoretic PIR as a layer of indirection between a user and their nym - allowing users to retrieve mail sent to their nym with information-theoretic privacy guarantees. Tor-PIR \cite{MittalOTBG11} uses PIR to distribute information about servers without forcing users to download the entire directory. 

\section{Privacy Goals}
The goal of this system is to provide a method for secure communication between parties through a central server with low latency and low communication overhead. We satisfy these requirements by assuming the intermediate server may be compromised. We define secure communication as thus \textbf{[6]}: FIX THIS CITE. Not sure which one it is.
\\\\\textbf{Communication Privacy:} Any party Eve cannot read the contents of intercepted messages sent between any two parties, Alice and Bob. 
\\\textbf{Participant Privacy:} This is also called \textbf{Unobservability} and \textbf{Untraceability}. Any party Eve cannot determine with probability $p > \epsilon$ that Alice and Bob are communicating, given any chosen $\epsilon$ with a clear lower bound of $\epsilon > 1/N$. The ability of multiple participants to collude and determine this with $p > \epsilon$ must be well defined.
\\\textbf{Destination Privacy:} Any party Eve in the network cannot determine the final destination of any party Alice's messages. This is a less stringent requirement than Participant Privacy.

\section{The Na\"ive Protocol}
Many of the developed P2P techniques can be adapted by using a pseudo-P2P protocol, by having peers communicate with each other indirectly through the central server. 

In P2P protocols, delivering a message via a chain of peers or servers is a standard method to achieve anonymity. In this system we'll use terminology from Tor and call the chain of peers a message passes through a $circuit$. A pseudo-P2P circuit then consists of an alternating chain of peer-server and server-peer communications.

\begin{figure}[ht]
  \begin{center}
    \begin{tikzpicture}[scale=0.2]
      \tikzstyle{every node}+=[inner sep=0pt]
      \draw [black] (15.3,-22.1) circle (3);
      \draw (15.3,-22.1) node {$Peer_a$};
      \draw [black] (22.7,-22.1) circle (3);
      \draw (22.7,-22.1) node {$S_1$};
      \draw [black] (30,-22.1) circle (3);
      \draw (30,-22.1) node {$Peer_b$};
      \draw [black] (37.2,-22.1) circle (3);
      \draw (37.2,-22.1) node {$S_1$};
      \draw [black] (44.5,-22.1) circle (3);
      \draw (44.5,-22.1) node {$Peer_c$};
      \draw [black] (18.3,-22.1) -- (19.7,-22.1);
      \fill [black] (19.7,-22.1) -- (18.9,-21.6) -- (18.9,-22.6);
      \draw [black] (25.7,-22.1) -- (27,-22.1);
      \fill [black] (27,-22.1) -- (26.2,-21.6) -- (26.2,-22.6);
      \draw [black] (33,-22.1) -- (34.2,-22.1);
      \fill [black] (34.2,-22.1) -- (33.4,-21.6) -- (33.4,-22.6);
      \draw [black] (40.2,-22.1) -- (41.5,-22.1);
      \fill [black] (41.5,-22.1) -- (40.7,-21.6) -- (40.7,-22.6);
    \end{tikzpicture}
  \end{center}
  \caption{A simple pseudo-P2P circuit}
\end{figure}


\subsection{Basic Protocol}
Assume that Alice has obtained Bob's public key and unique ID while maintaining her anonymity. This could be done using a public keyserver of some kind, or perhaps they have exchanged keys in advance through some other channel. Assume also that Alice can obtain the public keys and IDs for $n \le N$ peers at random while hiding her choice from Surge. 

Alice can then send a message to Bob that will follow the path $A \rightarrow P_1 \rightarrow S \rightarrow ... \rightarrow S \rightarrow P_n \rightarrow B$ by sending the following message to Surge: 
\\
Let $M = E_{KRA}[  time || nonce || message ]$
\\Let $F_{ij}[x] = E_{KUi}[ ID_j || E_{KUj}[ x ] ]$
\\
Alice sends: $F_{S1}[F_{S2}[...F_{nB}[ M ]]]$ to Surge. 

Each successive party receives a message and an ID to forward that message to, and only that party can read its message. Importantly, any Penguin or Proletariat without collusion from Surge doesn't gain any information about the source or destination of the message it's passing along. 

Note that Surge can't track a message by its contents, since it gets decrypted and changed by each successive peer. 

In this system, peers operate exactly as Mixes in the literature \cite{chaum-mix} . That is, they prevent traffic correlation by removing a layer of encryption, prevent relay attacks [[[something]]], as well (as we will discuss) by reordering and batching messages. 
\subsection{Security Flaws}
Here we'll perform a simplified analysis of the security flaws of the basic, na\"ive system described so far. 
Let $P_{AB}$ be the probability that Alice sent a given message that was delivered to to Bob. 
\begin{enumerate}
\item\textbf{Linear Chain.} If we assume that Alice's message is the only message sent by any of $p_1 \ldots p_n$ where $p_i$ is a peer, Surge can determine that $P_{AB} > (n+1)^{-1} \gg 1/N$. This is because Surge knows that one of $A \cup \{p_1 \ldots p_n\}$ talked to Bob.
\item\textbf{Collusion.} If $s$ peers collude with Surge to form The Fort, then The Fort can determine on average (depending on which peers Alice picked), that $P_{AB} > (n/(N-s)+1)^{-1}$ - that is, Alice has a chance $1 - (N-s)/N$ of each peer being compromised and not contributing to her privacy.
\item\textbf{Timing.} Even if $p_1 ... p_n$ are sending other messages, if Surge knows the probability distribution of the peer delay between receiving a message and forwarding it, he can discover the increased probability that Alice and Bob are talking. 
\item\textbf{Multiple Communications.} If Alice sends another message to Bob, or Bob back to Alice, the chance that they are communicating increases exponentially. 
\item\textbf{Man in the Middle.} If Alice acquries Bob's public key from Surge (and vice-versa), there's nothing to stop Surge from mounting a Man in the Middle attack given this simple model. 
\end{enumerate}
This is fairly poor security. If Alice chooses $n = 5$, then if her chosen peers send no other messages until hers is delivered, Surge knows $P_{AB} > 1/6$ chance that Alice is talking to Bob. If $60\%$ of peers are part of the Fort, then Surge possibly knows $P_{AB} = 1$ if $n \subset s$, but the expectation is $E[P_{AB}] = 1/3$ which is very poor anonymity.

\subsection{Solutions}
To begin solving these problems, we will need to change the protocol so that any non-Penguin peer will always wait until it can send \textbf{two or more messages simultaneously}. This is equivilant to turning each peer into a 2-threshold mix. \cite{TODO}

If we assume that The Fort has not been established (no peers are colluding with Surge), then Alice only needs to choose $n = log(N)$ to remain anonymous from Surge. If every node sends 2 messages at once, and her message passes through $log(N)$ nodes, then there are $2^n = 2^{log(n)} = N$ possible messages that Alice sent, and some $< N$ possible destinations. The likelihood is that in $log(N)$ steps from Alice, there will be less than $2^n = N$ unique recipients of messages, but we can adjust for this by increasing the number of nodes $n$ we choose. If every node has an average unique branching factor of $z$ rather than $2$, we can just set $n = log_z(N)$ and then $z^{log_z(N)} = 1/N$. Then, the size of Alice's anonymity probability distribution is $\approx 1$ since the sender probabilities are roughly uniform.

In this way Surge gains no information about the sender of the message. If Surge knows Alice will choose $n = log(N)$, then he can rule out any peer in the chain with distance less than $n$ from Alice, and then $P_{AB} = 2^{-(log(N)-1)} = 2/N$, and $S = - \frac{1}{4} log(\frac{1}{2N})$ which is still reasonable, though Alice could compensate further by randomly choosing the length of her circuit. 

\subsection{The Fort} Assuming the set $S$ of peers colludes with the server where $s = |S| > n$, and Alice chooses her circuit $C$ of peers randomly (where $|C| = n$), there is some chance that all chosen peers are colluding with Surge $(R \subset S)$ and so Alice's identity is completely compromised $(P_{AB} = 1$ and $S = 0)$. 

Let $\phi$ be the proportion of peers who are colluding with Surge. Then $s = \phi N$ peers are part of The Fort, and on average $(1 - \phi)n$ of $n$ chosen peers still help maintain privacy, leading to the expectation $E[P_{AB}] = 2^{-(1 - \phi) log(N)}$. 

The chance Surge can tell with probability greater than $\gamma$ that Alice and Bob are talking to each other, $p(P_{AB} > \gamma)$ requires Alice choosing $x$ Fort members as peers. 

Each peer has a probability $\phi$ of being part of the Fort, so Alice choosing $x$ or more colluding peers occurs with probability $\sum\limits_{i=x}^n\phi^i$ where 
\\ $P_{AB} = 2^{-(n - x)} = 2^{-(log(N) - x)} = \gamma$
\\ $ \Rightarrow x = 2^{loglog(N)/\gamma}$

\begin{figure}[ht]
  \begin{tabular}{| l | l | l | l | l | l |}
    \hline
    $\phi$ & N & $E[P_{AB}]$ & x & n & $p(P_{AB} > 0.5)$ \\\hline
    0.5 & 1000 & 0.031 & 4 & 10 & 0.12\\
    0.5 & 10000 & 0.01 & 4 & 14 & 0.12\\
    0.5 & 100000 & 0.003 & 5 & 17 & 0.06\\
    \hline
  \end{tabular}
  \caption{Table 42.42 - Probabilities things are bad}
\end{figure}

While less than ideal, this is not unreasonable. The chance that Surge, having $50\%$ of 1000 peers colluding with him, can tell that Alice is talking to Bob with probability greater than $0.5$ is only $12\%$. 

\begin{comment}
  TODO: Apply PIR to obtain security guarantees even when $R \subset S$
\end{comment}

\subsection{Peer Discovery and MITM brainstorming}

Lying about who's online - If you want to send a message to a real node ``B'' but B is not listed as online, you won't send a message. However, if he lists ``B'' as online, ``B'' can be used to route messages validly by everyone. 

Chain verification - Keep a web of trust with the length of the path to a person inversely proportional to how trusted they are. Share web of trust with those we communicate with - only share nodes with a certain level of trust, and then trust nodes discovered this way with diminished trust. 

If initial trust is only spread through person to person contact, then assigning negative trust is valuable because it reduces the value of colluding human nodes. 

* Have nodes sign messages as they pass through, so that the path can be tested/verified. 

\subsection{Peer Discovery}
Unfortunately, if peers discover eachother through Surge, he can ensure that any peer only knows about compromised peers (Effectively making $\phi = 1$).

This is a common problem in Onion routing schemes like Tor, as well as Mix networks. If directory servers collude with some routing servers, they can choose to only broadcast the existence of the compromised routing servers.

MixMinion \cite{minion-design} solves these problems by having a small group of directory servers that only update nightly, having servers sign each other's directories, and ensuring that users download entire directories. These solutions are not feasible in our case since the set of online users is constantly in flux, and is likely to be too large to be sent to every user. Tor \cite{tor-design} likewise has a small number of trusted directory servers that share infrequently updated, signed directories.



\subsection{Man in the Middle} If both Alice and Bob are online, then they could use Diffie-Hellman to ensure that Surge isn't acting as a Man in the Middle. However, we'd like to allow offline delivery of messages.

This requires some form of web of trust, or some means of verifying public keys without trusting Surge. 

Users should maintain a list of known keys to make stuff good. 

\subsection{Peers as Mixes}
As previously discussed, peers act as mixes in this system - inheriting both their benefits and vulnerabilities. Many types of mixes have been developed, and Serjantov \cite{trickle02} has compiled common attacks and solutions. 
A mix holds on to incoming messages until its \textbf{flush function} is satisfied, then it forwards some subset of its collected messages. Common attacks are variants of the $n - 1$, or $flooding$ attack, in which an attacker fills the mix with its own fake messages and then sends the 1 message he wishes to track. 

All known mix types are vulnerable to such exact attacks \cite{trickle02} -  attacks that allow an attacker to know whether his attack was successful or not and try again if not. Since in our threat model Surge has complete access to the message history of each peer as well as the ability to delay and insert as many messages as he desires, trying to prevent these attacks by implementing a better flush function is even more futile. 

Fortunately, due to the nature of this system we can provide almost complete protection with \textbf{cover traffic} \cite{trickle02}, or having each peer send dummy messages along with the messages it's forwarding. A peer will at minimum send one dummy message along with every real message, maintaining a branching factor greater than two at every hop. Typically, obtaining complete protection with cover traffic is difficult - it requires the mix to choose dummy message recipients uniformally from all users\cite{trickle02}. In our system, however, randomly and anonymously choosing other online peers is designed to be efficient.

It would also be possible to use inter-mix detours\cite{TODO}, having peers randomly decide to introduce new hops to prevent Surge from recognizing his own messages sent during an $n - 1$ attack. However, this reduces reliability, increases latency, and given the protection that cover traffic provides seems unnecessary in this system. 

\section{Applying PIR}
\subsection{PIR usage}
An obvious way to utilize PIR for anonymous communication is as a ``Dead Drop''. If we have a PIR server Charlie, Alice could write her messages to block $i$ in Charlie's PIR database, then Bob could request block $i$ anonymously. This could enable us to increase the size of Alice's anonymity set (retaining a uniform distribution of probabilities, as well) while reducing our circuit length significantly. 

\subsection{PIR issues}
There are, however, several problems with this configuration.

First, Alice must communicate Charlie's ID and $i$ to Bob anonymously. This could happen via the pseudo-P2P protocol as above. 

Second, Alice and Bob both start talking to Charlie around the same time. If Charlie suspects Alice and Bob are talking to each other, he can easily create a fake PIR database for all of Alice's inserts and all of Bob's retrievals, and if they continue to communicate normally he has discovered a connection. 


\section{Future Work}
\begin{description}
\item[Pseudonymity.] Allow for parties to communicate securely without knowing each other's identities. Currently our system relies heavily (at least when a person first enters the network) on the fact that the person initiating the communication knows the person's key with whom he wants to communciate.

\item[Faster circuits.] Like Tor, we could use layers of symmetric encryption between successive pairs of peers in a circuit. Using a public/symmetric system like Tor could help with pseudonymity as well. Currently we are doing a lot of public/private key encryption which is slow.

\item[DoS.] We would like to address the issue of DoS attacks against networks by requiring messages to be accompanied by a proof of work. This would allow us to require that the messages being sent are by computers that are also helping to suport the network.
\end{description}

\section{Conclusion}
Conclusion words here about our network which is basically whatever we have in the introduction

\newpage

\bibliography{paper.bib}
\bibliographystyle{unsrt}
\end{document}
